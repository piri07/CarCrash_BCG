# -*- coding: utf-8 -*-
"""Analytics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PJcjhFq9_T6ND4X0C3Shw_cRk0VaUx-p
"""

# !pip install pyspark

# prompt: Initiate spark session

from pyspark.sql import SparkSession
from pyspark.sql.functions import col, count,rank,desc
from pyspark.sql.window import Window
import pandas as pd
import numpy as np
import csv
import os

spark = SparkSession.builder.appName("AnalysisApp").getOrCreate()
# spark

csv_files = [
    "/content/drive/MyDrive/Colab Notebooks/Data/Charges_use.csv",
    "/content/drive/MyDrive/Colab Notebooks/Data/Damages_use.csv",
    "/content/drive/MyDrive/Colab Notebooks/Data/Endorse_use.csv",
    "/content/drive/MyDrive/Colab Notebooks/Data/Primary_Person_use.csv",
    "/content/drive/MyDrive/Colab Notebooks/Data/Restrict_use.csv",
    "/content/drive/MyDrive/Colab Notebooks/Data/Units_use.csv"
]
dataframes = {}
for file_path in csv_files:
    # Extract filename without extension
    filename = os.path.splitext(os.path.basename(file_path))[0]
    df_name = f"df_{filename}"  # Create a name like df_sales, df_customers, etc.
    dataframes[df_name] = spark.read.csv(file_path, header=True, inferSchema=True)

# dataframes["df_Charges_use"].show()

def analytics1(df_name):
    df_Primary_Person_use = dataframes[df_name]
    filtered_df = df_Primary_Person_use.filter((col("PRSN_GNDR_ID") == "MALE") & (col("PRSN_INJRY_SEV_ID") == "KILLED"))
    # Group by crash_id and count the number of males killed per crash
    grouped_df = filtered_df.groupBy("CRASH_ID").count()
    # Filter for crashes where males killed > 2
    result_df = grouped_df.filter(col("count") >= 2)
    # Count the number of such crashes
    crash_count = result_df.count()
    print(f"Number of crashes where males killed >= 2 are: {crash_count}")
    return crash_count
analytics1("df_Primary_Person_use")

def analytics2(df_name):
  df_Units_use = dataframes[df_name]
  filtered_df = df_Units_use.filter((col("VEH_BODY_STYL_ID") == "MOTORCYCLE") | (col("VEH_BODY_STYL_ID") == "POLICE MOTORCYCLE"))
  # print(filtered_df.show())
  unique_df = filtered_df.dropDuplicates(['CRASH_ID'])
  # print(unique_df.show())
  two_wheelers_crashed = unique_df.count()
  print(f"Number of crashes which involved 2 Wheelers are : {two_wheelers_crashed}")
  return two_wheelers_crashed
analytics2("df_Units_use")

def analytics3(df_name1,df_name2):
  df_Primary_Person_use = dataframes[df_name1]
  df_Units_use = dataframes[df_name2]
  df_joined = df_Primary_Person_use.join(df_Units_use, on="CRASH_ID", how="inner")
  df_joined = df_joined.filter((col("PRSN_TYPE_ID")=="DRIVER") & (col("PRSN_AIRBAG_ID")=="NOT DEPLOYED")&(col("PRSN_INJRY_SEV_ID") == "KILLED"))
  grouped_df = df_joined.groupBy("VEH_MAKE_ID").count()
  top_5_df = grouped_df.orderBy(col("count").desc()).limit(5)
  top_5_rows = top_5_df.collect()
  top_5_values = [row['VEH_MAKE_ID'] for row in top_5_rows]
  print("Top 5 Vehicle Manufacturer where airbags did not deploy and driver died are:")
  print(top_5_values)
  return top_5_values
analytics3("df_Primary_Person_use","df_Units_use")

def analytics4(df_name1,df_name2):
  df_Primary_Person_use = dataframes[df_name1]
  df_Charges_use = dataframes[df_name2]
  df_joined = df_Primary_Person_use.join(df_Charges_use, on="CRASH_ID", how="inner")
  filter_df = df_joined.filter((col("DRVR_LIC_CLS_ID")!="UNLICENSED")& (col("DRVR_LIC_CLS_ID")!="UNKNOWN") &(col("PRSN_TYPE_ID")=="DRIVER"))
  hit_and_run_df = filter_df.filter(col("CHARGE").contains("HIT AND RUN"))
  hit_and_run_df = hit_and_run_df.dropDuplicates(['CRASH_ID'])
  no_of_vehicles = hit_and_run_df.count()
  print(f"Number of Vehicles involved in a Crash having valid driver's license : {no_of_vehicles}")
  return no_of_vehicles
analytics4("df_Primary_Person_use","df_Charges_use")

def analytics5(df_name1):
  df_Primary_Person_use = dataframes[df_name1]
  df_Primary_Person_use = df_Primary_Person_use.filter((col("PRSN_GNDR_ID") != "FEMALE"))
  accidents_count_df = df_Primary_Person_use.groupBy("DRVR_LIC_STATE_ID").agg(count("CRASH_ID").alias("accident_count"))
  max_accident_state = accidents_count_df.orderBy(col("accident_count").desc()).limit(1)
  max_accident_state_value = max_accident_state.collect()[0]["DRVR_LIC_STATE_ID"]
  max_accident_state_count = max_accident_state.collect()[0]["accident_count"]
  print(f"State with highest non-female accident is: {max_accident_state_value}")
  print(f"Number of crashes are: {max_accident_state_count}")
analytics5("df_Primary_Person_use")

def analytics6(df_name1,df_name2):
  df_Primary_Person_use = dataframes[df_name1]
  df_Units_use = dataframes[df_name2]
  df_joined = df_Primary_Person_use.join(df_Units_use, on="CRASH_ID", how="inner")
  df_joined = df_joined.filter((col("PRSN_INJRY_SEV_ID")!="NOT INJURED") & (col("PRSN_INJRY_SEV_ID")!="UNKNOWN")& (col("PRSN_INJRY_SEV_ID")!="NA"))
  unique_df = df_joined.dropDuplicates(["CRASH_ID"])
  injury_count_df = unique_df.groupBy("VEH_MAKE_ID").agg(count("CRASH_ID").alias("injury_count"))
  sorted_df = injury_count_df.orderBy(col("injury_count").desc())
  top_3_to_5_df = sorted_df.limit(5).subtract(sorted_df.limit(2))
  top_3_to_5 = top_3_to_5_df.collect()
  print("Top 3rd to 5th Vehicle makers which cause the largest number of injuries including death are:")
  for row in top_3_to_5:
      print(f"Vehicle Maker: {row['VEH_MAKE_ID']}, Number of Injuries/Deaths: {row['injury_count']}")
analytics6("df_Primary_Person_use","df_Units_use")

def analytics7(df_name1,df_name2):
  df_Primary_Person_use = dataframes[df_name1]
  df_Units_use = dataframes[df_name2]
  df_joined = df_Primary_Person_use.join(df_Units_use, on="CRASH_ID", how="inner")
  df_joined = df_joined.filter((col("VEH_BODY_STYL_ID")!="UNKNOWN") & (col("VEH_BODY_STYL_ID")!="NA") & (col("VEH_BODY_STYL_ID")!="NOT REPORTED"))
  ethnicity_count_df = df_joined.groupBy("VEH_BODY_STYL_ID", "PRSN_ETHNICITY_ID").agg(count("CRASH_ID").alias("ethnicity_count"))
  top_ethnic_group_df = ethnicity_count_df.withColumn("rank", rank().over(Window.partitionBy("VEH_BODY_STYL_ID").orderBy(desc("ethnicity_count"))))
  top_ethnic_group_df = top_ethnic_group_df.filter(col("rank") == 1).drop("rank")
  top_ethnic_group= top_ethnic_group_df.collect()
  print("Top ethnic groups for each vehicle body type are:")
  for row in top_ethnic_group:
      print(f"Body Style: {row['VEH_BODY_STYL_ID']}, Top Ethnic Group: {row['PRSN_ETHNICITY_ID']}, Count: {row['ethnicity_count']}")

analytics7("df_Primary_Person_use","df_Units_use")

def analytics8(df_name1):
  df_Primary_Person_use = dataframes[df_name1]
  df_filtered = df_Primary_Person_use.filter((col("PRSN_ALC_RSLT_ID")=="Positive")& (col("DRVR_ZIP")!="NULL"))
  unique_df = df_filtered.dropDuplicates(["CRASH_ID"])
  top_5_zip_codes = unique_df.groupby("DRVR_ZIP").count().orderBy(desc("count")).limit(5)
  top_5_zip_codes_list = top_5_zip_codes.collect()
  print("Top 5 ZIP codes with alcohol as the contributing factor to a crash:")
  for row in top_5_zip_codes_list:
      print(f"Driver Zip Code: {row['DRVR_ZIP']}, Count: {row['count']}")

analytics8("df_Primary_Person_use")